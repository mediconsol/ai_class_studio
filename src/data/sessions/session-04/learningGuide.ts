import { LearningGuide } from '../../types';

export const learningGuide: LearningGuide = {
  keyTakeaways: {
    title: 'AI의 한계와 위험 핵심 요약',
    points: [
      '"할루시네이션(환각)"은 AI가 그럴듯한 거짓말을 하는 현상입니다 - 자신있게 틀린 답을 내놓을 수 있습니다',
      'AI는 "최신 정보를 모릅니다" - 학습 데이터 기준 시점 이후의 정보는 알지 못합니다',
      'AI는 "판단할 수 없습니다" - 의학적 진단, 윤리적 판단, 복잡한 상황 분석은 불가능합니다',
      '"반드시 검증"이 필요합니다 - AI 결과는 참고만 하고, 전문가가 직접 확인해야 합니다',
      'AI는 "맥락을 이해하지 못합니다" - 환자의 전체 상황, 병원의 특수한 정책 등을 고려하지 못합니다',
    ],
  },

  practicalConnection: {
    title: '실무에서 이렇게 활용하세요',
    tips: [
      '할루시네이션 감지법: 수치, 날짜, 고유명사가 있으면 원본과 반드시 대조',
      '결과 검증 체크리스트: "원본 데이터와 일치?", "상식적으로 맞나?", "출처 확인 가능?"',
      '의심스러우면 재질문: 같은 내용을 다르게 물어보면 답이 달라질 수 있습니다',
      '최신 정보는 별도 확인: 최신 가이드라인, 신약 정보 등은 공식 출처에서 재확인',
      'AI는 보조만: 초안, 아이디어, 정리에만 활용하고 최종 판단은 사람이',
    ],
  },

  commonMistakes: {
    title: '이것만은 오해하지 마세요',
    mistakes: [
      {
        myth: 'AI가 자신있게 말하면 맞는 것이다',
        reality: 'AI는 틀린 답도 자신있게 제시합니다. 반드시 검증이 필요합니다',
      },
      {
        myth: 'AI가 최신 의학 정보를 알고 있다',
        reality: 'AI는 학습 시점까지의 데이터만 알고, 최신 정보는 모릅니다',
      },
      {
        myth: 'AI에게 판단을 맡길 수 있다',
        reality: 'AI는 판단 도구가 아닙니다. 의학적 판단은 반드시 의료인이 해야 합니다',
      },
      {
        myth: '할루시네이션은 드물게 일어난다',
        reality: '할루시네이션은 언제든 발생할 수 있습니다. 항상 경계해야 합니다',
      },
    ],
  },

  selfCheck: {
    title: '스스로 점검해보세요',
    questions: [
      '할루시네이션이 무엇인지, 왜 발생하는지 설명할 수 있나요?',
      'AI 결과를 검증하는 구체적인 방법 3가지 이상을 말할 수 있나요?',
      'AI가 할 수 없는 것(판단, 최신정보, 맥락이해)을 정확히 알고 있나요?',
      'AI 결과를 그대로 사용했을 때의 위험성을 이해하고 있나요?',
      '동료에게 "AI를 조심해서 써야 하는 이유"를 설명할 수 있나요?',
    ],
  },
};
