import { Slide } from '../../types';

export const slides: Slide[] = [
  // 도입부 (6분)
  {
    id: 1,
    phase: 'intro',
    title: '강의 오프닝',
    screenContent: [
      '의료기관 업무 혁신을 위한 생성형 AI 실무 활용',
      '',
      '4강. AI 활용의 윤리와 보안',
    ],
    script: `4강을 시작하겠습니다.

앞선 세 강의에서 AI로 업무를 줄이는 방법을 이야기했습니다.

1강에서는 "판단은 사람이, 정리는 AI가"라는 원칙을 배웠습니다.
2강에서는 프롬프트 쓰는 법, 역할-대상-형식-주의사항을 배웠습니다.
3강에서는 문서업무 자동화, 패턴을 찾아서 형식을 고정하는 방법을 배웠습니다.

그런데 이쯤 되면 이 질문이 반드시 따라옵니다.

"이거, 써도 되는 거 맞습니까?"
"환자 정보 넣어도 괜찮은 겁니까?"
"뭔가 문제 생기면 어떻게 합니까?"
"나중에 책임지라고 하면 어떻게 합니까?"

당연한 질문입니다. 새로운 도구를 쓸 때 이런 걱정이 안 드는 게 이상한 겁니다. 특히 의료기관에서는 더 그렇습니다.

오늘은 그 질문에 명확히 답하는 시간입니다.

미리 말씀드리겠습니다.

오늘은 겁주려는 이야기가 아닙니다.

"이거 하면 안 된다, 저거 하면 안 된다" 하면서 무섭게 만들려는 게 아닙니다. "법 위반이다, 처벌받는다" 이런 식으로 겁주려는 게 아닙니다.

기준을 잡아드리는 이야기입니다.

기준이 있으면 편합니다. "이건 된다, 이건 안 된다"가 명확하면, 오히려 마음 편하게 AI를 쓸 수 있습니다. 기준이 없으니까 불안한 겁니다. 기준이 있으면 그 안에서 자유롭게 씁니다.

오늘 그 기준을 확실히 잡아드리겠습니다.`,
  },

  {
    id: 2,
    phase: 'intro',
    title: '의료현장에서 AI 윤리가 특히 중요한 이유',
    screenContent: [
      '의료기관이 다루는 정보의 특수성',
      '',
      '1. 개인정보 - 가장 민감한 정보',
      '2. 의료정보 - 건강과 생명에 직결',
      '3. 신뢰 - 환자가 병원을 믿고 맡긴 정보',
    ],
    script: `왜 의료현장에서 AI 윤리가 특히 중요합니까?

다른 업종보다 더 조심해야 하는 이유가 있습니다. 세 가지입니다.

첫째, 개인정보입니다.

병원은 가장 민감한 개인정보를 다루는 곳입니다. 이름, 주민번호, 연락처. 이건 어디서나 다룹니다. 은행도 다루고, 통신사도 다룹니다.

그런데 병원은 여기에 더해서 건강 정보까지 다룹니다. 어떤 병이 있는지, 어떤 약을 먹는지, 어떤 수술을 받았는지. 가족력까지 알고 있습니다.

이런 정보가 외부로 나가면 단순한 개인정보 유출이 아닙니다. 건강 정보 유출입니다. 취업에 불이익을 받을 수 있고, 보험 가입이 거절될 수 있고, 사회적 낙인이 찍힐 수 있습니다. 정신건강 정보라면 더 심각합니다.

그래서 의료 개인정보는 다른 어떤 개인정보보다 더 민감하게 다뤄야 합니다. 법적으로도 의료정보는 민감정보로 분류되어 더 엄격하게 관리됩니다.

둘째, 의료정보입니다.

의료정보는 건강과 생명에 직결되는 정보입니다. 잘못된 정보가 퍼지면 어떻게 됩니까?

"이 약이랑 저 약 같이 먹어도 된다" - 잘못된 정보면 생명이 위험할 수 있습니다.
"이 증상이면 이 병이다" - 잘못된 판단이면 치료 시기를 놓칠 수 있습니다.
"이 정도 통증은 괜찮다" - 잘못된 정보면 악화될 수 있습니다.

AI가 그럴듯하게 틀릴 수 있다고 했습니다. 1강에서 '환각(Hallucination)' 이야기를 했습니다. 일반적인 분야에서 환각은 불편한 수준입니다. 하지만 의료 영역에서 환각은 치명적일 수 있습니다.

셋째, 신뢰입니다.

환자는 병원을 믿고 정보를 맡깁니다. "내 건강 정보, 병원에서 잘 관리해주겠지." 이 신뢰가 무너지면 어떻게 됩니까?

환자가 솔직하게 증상을 말하지 않게 됩니다. "혹시 내 정보가 새나가면 어떻게 하지?" 하고 걱정하기 때문입니다. 증상을 숨기면 정확한 진단이 어렵습니다. 신뢰가 무너지면 의료 자체가 어려워집니다.

의료기관은 다른 어떤 조직보다 정보에 대한 신뢰가 중요한 곳입니다. AI를 쓰는 순간에도 이 원칙은 변하지 않습니다.`,
  },

  // 본론 1: AI 사용의 3대 원칙 (10분)
  {
    id: 3,
    phase: 'understand',
    title: 'AI 윤리의 실체',
    screenContent: [
      'AI 윤리 = 법 조항 외우기 ❌',
      'AI 윤리 = 실무 기준 갖추기 ⭕',
    ],
    script: `'AI 윤리'라고 하면 무엇이 떠오르십니까?

"개인정보보호법..."
"의료법 위반..."
"처벌 조항..."

법 조항, 규정, 처벌. 이런 단어들이 먼저 생각나실 겁니다. 뭔가 무겁고 복잡한 것 같습니다.

물론 법적인 부분도 중요합니다. 알아두셔야 합니다.

하지만 현장에서 실제로 필요한 건 무엇입니까?

법 조항 전체를 외우는 게 아니라, "이렇게 하면 된다 / 안 된다"는 실무 기준입니다.

환자 기록 정리할 때, 일일이 "이게 개인정보보호법 몇 조에 해당하나?" 생각하면서 할 수 없습니다. 그럴 시간이 없습니다. 바쁜 현장에서 법조문을 펴볼 수 없습니다.

그냥 "이건 된다, 이건 안 된다"라는 명확한 기준이 있으면 됩니다. 간단한 체크리스트가 있으면 됩니다.

오늘은 법 이야기보다 현장에서 바로 적용할 수 있는 기준을 드리겠습니다.

이 기준만 지키시면, 법적으로도 문제없고, 윤리적으로도 문제없습니다. 복잡하게 생각하실 필요 없습니다.`,
  },

  {
    id: 4,
    phase: 'understand',
    title: '의료기관 AI 사용의 3대 원칙',
    screenContent: [
      '1. 개인정보는 입력하지 않는다',
      '2. 판단은 AI에게 맡기지 않는다',
      '3. 최종 책임은 사람이 진다',
    ],
    script: `의료기관에서 AI를 쓸 때 지켜야 할 원칙입니다.

딱 세 가지만 기억하시면 됩니다. 세 가지입니다. 이것만 기억하시면 됩니다.

첫째, 개인정보는 입력하지 않는다.

환자 실명, 주민번호, 연락처 같은 정보는 AI에 넣지 않습니다.

ChatGPT든 Claude든, 외부 AI 서비스에 개인정보를 입력하면 그 정보가 어디로 가는지 우리가 통제할 수 없습니다. 서버가 외국에 있을 수도 있고, 어떻게 저장되는지 알 수 없습니다.

둘째, 판단은 AI에게 맡기지 않는다.

진단, 처방, 결정은 AI가 하면 안 됩니다.

AI는 정리를 잘합니다. 하지만 판단은 못합니다. "이 환자에게 이 약을 줘야 할까?" 이런 판단은 의료인만 할 수 있습니다. AI가 대신해줄 수 없습니다.

셋째, 최종 책임은 사람이 진다.

AI가 만든 결과물도 사람이 확인하고 책임집니다.

AI가 아무리 잘 만들어줘도, 그걸 그대로 쓰면 안 됩니다. 검토하고, 수정하고, 승인하는 건 사람의 몫입니다. "AI가 그렇게 만들어줬다"는 변명이 안 됩니다.

이 세 가지만 기억하셔도 의료기관에서 AI를 쓰는 데 큰 문제는 생기지 않습니다.

오늘 강의는 이 세 가지 원칙을 구체화하는 시간입니다. 이게 실제로 어떻게 적용되는지 보여드리겠습니다.`,
  },

  {
    id: 5,
    phase: 'understand',
    title: '개인정보의 범위',
    screenContent: [
      '개인정보 = "이 정보로 특정 사람을 알아볼 수 있는가?"',
      '',
      '• 실명, 주민번호, 연락처 → 명백한 개인정보',
      '• 진단명 + 식별정보 조합 → 특정 가능하면 개인정보',
    ],
    script: `많은 분들이 헷갈려 하시는 부분입니다.

"어디까지가 개인정보입니까?"
"이름만 빼면 됩니까?"
"나이는 괜찮습니까?"
"진단명은요?"

기준은 하나입니다.

"이 정보로 특정 사람을 알아볼 수 있느냐?"

이게 핵심 기준입니다. 이것만 생각하시면 됩니다.

실명 - 당연히 개인정보입니다. "김철수"라고 쓰면 특정인을 알 수 있습니다.

주민번호 - 가장 민감한 정보입니다. 절대 입력하면 안 됩니다. 이건 말할 것도 없습니다.

연락처 - 전화번호, 주소 모두 포함됩니다. 연락처만 있어도 특정 가능합니다.

그런데 여기서 중요한 게 하나 더 있습니다.

"진단명 + 식별 정보" 조합입니다.

"당뇨"라는 진단명 자체는 개인정보가 아닙니다. 당뇨 환자가 수백만 명인데, 이걸로 누군지 알 수 없습니다. "당뇨"라고만 쓰면 괜찮습니다.

하지만 이렇게 조합하면 어떻게 됩니까?

"김OO, 80세, 남성, 당뇨"

우리 병원에 80대 남성 김씨 당뇨 환자가 몇 명이나 있습니까? 아마 몇 명 안 될 겁니다. 특정 가능성이 생깁니다. 몇 명 추려서 찾아낼 수 있습니다.

정보 하나하나는 괜찮아도, 조합하면 특정 가능해지는 경우가 있습니다. 이런 경우도 입력하면 안 됩니다.

핵심 기준: "이 정보로 누군지 알아볼 수 있는가?"

알아볼 수 있으면 입력하지 않습니다. 알아볼 수 없으면 괜찮습니다.`,
  },

  {
    id: 6,
    phase: 'understand',
    title: '안전한 데이터 처리 방법',
    screenContent: [
      '방법 1: 가명 처리 - "환자 A", "김OO"',
      '방법 2: 비식별화 - "82세" → "80대"',
      '방법 3: 예시 데이터 - 실제 환자와 무관한 가상 정보',
    ],
    script: `"그러면 어떻게 해야 합니까?"
"환자 정보를 전혀 안 쓰면 AI를 쓸 수가 없지 않습니까?"

맞습니다. 업무에 AI를 쓰려면 어떤 형태로든 정보가 들어가야 합니다. 정보 없이는 AI가 할 수 있는 게 없습니다.

방법이 있습니다. 세 가지입니다.

첫째, 가명 처리입니다.

실명 대신 "환자 A", "김OO" 같은 가명을 씁니다.

"김철수 환자 기록 정리해줘" ❌
"환자 A 기록 정리해줘" ⭕

이름만 바꿔도 특정 가능성이 크게 줄어듭니다. 간단한 방법인데 효과가 큽니다.

둘째, 비식별화입니다.

구체적인 정보를 범위로 바꿉니다.

"82세" → "80대"
"12월 15일" → "12월 중순"
"서울시 강남구 OO동" → "서울 거주"

범위로 바꾸면 특정하기 어려워집니다. 82세는 한 명일 수 있지만, 80대는 많습니다.

셋째, 예시 데이터입니다.

실제 환자 정보 대신 교육용 예시 데이터를 씁니다.

"환자 A, 70대 남성, 고혈압 약 복용 중"

이런 식으로 가상의 환자 정보를 만들어서 쓰는 겁니다. 실제 환자와 1:1로 대응되지 않으면 개인정보가 아닙니다. 완전히 만들어낸 가상 정보입니다.

이 세 가지 방법만 쓰면 AI를 충분히 안전하게 활용할 수 있습니다.

6강부터 실습할 때도 모두 이 방식으로 예제 데이터를 사용합니다. 실제 환자 정보는 절대 쓰지 않습니다.`,
  },

  {
    id: 7,
    phase: 'understand',
    title: '명확한 금지 사항',
    screenContent: [
      '❌ 절대 하면 안 되는 것',
      '',
      '1. 환자 실명 그대로 입력',
      '2. 진단·처방 요청',
      '3. 책임 표현이 들어간 문서 요청',
    ],
    script: `명확히 피해야 할 사용 방식을 정리하겠습니다.

이건 절대 하면 안 되는 것들입니다. 예외 없습니다.

첫째, 환자 실명 그대로 입력.

"김철수 환자의 간호기록을 정리해줘"

이렇게 쓰면 안 됩니다.

"김철수"라는 실명이 외부 AI 서버로 전송됩니다. 그 정보가 어디에 저장되고, 누가 볼 수 있는지 우리가 통제할 수 없습니다. 나중에 어디서 어떻게 쓰일지 모릅니다.

둘째, 진단·처방 요청.

"이 환자 어떤 약 줘야 해?"
"이 증상이면 어떤 검사가 필요해?"
"이 환자 진단이 뭐야?"

이런 요청은 절대 안 됩니다. 교육 목적이라고 해도 적절하지 않습니다.

AI가 그럴듯하게 대답할 수 있습니다. 그런데 그게 틀릴 수 있습니다. 잘못된 의료 정보가 머릿속에 남으면 위험합니다. 나중에 헷갈릴 수 있습니다.

셋째, 책임 표현이 들어간 문서 요청.

"~의 책임이다"
"~해야 한다"
"~를 권고한다"

이런 표현을 AI가 만들게 하면 안 됩니다.

AI가 "이렇게 해야 합니다"라고 쓰면, 마치 AI가 책임지는 것처럼 보일 수 있습니다. 하지만 AI는 책임을 질 수 없습니다. 책임은 사람이 지는 겁니다. "AI가 권고했다"는 건 말이 안 됩니다.

이 세 가지는 명확한 금지 사항입니다.

실명 입력, 진단/처방 요청, 책임 표현. 이것만 피하셔도 대부분의 위험은 피할 수 있습니다.`,
  },

  {
    id: 8,
    phase: 'understand',
    title: 'AI가 잘 도와주는 업무 영역',
    screenContent: [
      '⭕ 안전하게 활용 가능한 영역',
      '',
      '• 기록 요약 - 이미 작성된 기록 정리',
      '• 문서 초안 - 보고서, 안내문의 첫 버전',
      '• 교육자료 정리 - 일반적인 의학 지식 정리',
      '',
      '키워드: 정리, 요약, 초안',
    ],
    script: `지금까지 "안 되는 것"을 이야기했습니다. "이건 안 되고, 저건 안 되고..."

그러면 뭘 할 수 있습니까?

반대로, 이런 작업들은 AI가 가장 잘 도와주는 영역입니다. 마음 편하게 쓰셔도 됩니다.

기록 요약

이미 작성된 기록을 정리하는 일입니다.

"이 간호기록을 인수인계용으로 요약해줘"

판단이 아니라 정리입니다. AI가 잘하는 영역입니다. 이미 있는 내용을 깔끔하게 정리해주는 겁니다.

문서 초안

보고서, 안내문의 첫 버전을 잡는 일입니다.

"수술 전 금식 안내문 초안 작성해줘"

백지에서 시작하는 것보다 훨씬 빠릅니다. 초안 잡아주면 검토해서 다듬으면 됩니다.

교육자료 정리

지침을 쉽게 풀어쓰거나, 교육 내용을 정리하는 일입니다.

"당뇨 환자 식이요법 교육자료 만들어줘"

일반적인 의학 지식을 정리하는 거라 개인정보 이슈가 없습니다. 특정 환자가 아니라 일반적인 내용입니다.

키워드 세 가지를 기억하십시오.

정리, 요약, 초안.

이 범위 안에서는 AI를 마음껏 활용하셔도 됩니다. 이 범위가 AI의 영역입니다.`,
  },

  // 본론 2: 시나리오 판단 연습 (15분)
  {
    id: 9,
    phase: 'practice',
    title: '위험과 안전의 경계',
    screenContent: [
      '같은 주제, 다른 결과',
      '',
      '❌ "김OO 환자, 당뇨 진단인데 약 추천해줘"',
      '⭕ "당뇨 환자 교육자료 초안을 작성해줘"',
    ],
    script: `실제 예시로 비교해보겠습니다.

같은 "당뇨" 관련 요청인데, 하나는 위험하고 하나는 안전합니다. 문장 하나 차이입니다.

위험한 예시:

"김OO 환자, 당뇨 진단인데 약 추천해줘."

이건 세 가지가 다 잘못됐습니다.

1. 실명("김OO")이 들어갔습니다 - 개인정보 문제
2. 진단("당뇨")이 실명과 연결됐습니다 - 특정 가능
3. 처방("약 추천")을 요청했습니다 - 의료 판단 요청

개인정보 + 의료판단 요청. 최악의 조합입니다. 할 수 있는 실수를 다 한 겁니다.

안전한 예시:

"당뇨 환자 교육자료 초안을 작성해줘."

이건 괜찮습니다.

1. 개인정보가 없습니다 - "당뇨 환자"는 특정인이 아닙니다
2. 판단 요청이 아닙니다 - "초안 작성"은 정리 업무입니다
3. 일반적인 교육자료 정리 업무입니다

문장 하나 차이지만 의미는 완전히 다릅니다.

경계선이 무엇입니까?

"AI에게 판단을 요구하는 순간" 위험해집니다.

정리해달라는 건 괜찮습니다. 요약해달라는 건 괜찮습니다. 초안 잡아달라는 건 괜찮습니다.

"어떻게 해야 해?", "뭐가 좋아?", "추천해줘" - 이런 판단 요청이 들어가면 위험해집니다.`,
  },

  {
    id: 10,
    phase: 'practice',
    title: '시나리오 판단 연습 안내',
    screenContent: [
      '다음 상황, 안전할까요?',
      '',
      '네 가지 시나리오를 보고 판단해보겠습니다.',
    ],
    script: `지금부터 실제 상황을 보고 안전한지 위험한지 판단하는 연습을 해보겠습니다.

제가 상황을 하나씩 보여드리겠습니다. 각 상황을 보시고, "이건 안전하다 / 위험하다" 판단해보십시오.

그 다음에 정답과 이유를 설명드리겠습니다.

실제 현장에서 이런 판단을 하셔야 하니까, 연습이 중요합니다. AI 쓰기 전에 "이거 해도 되나?" 순간적으로 판단할 수 있어야 합니다.

총 네 가지 시나리오를 보겠습니다.`,
  },

  {
    id: 11,
    phase: 'practice',
    title: '시나리오 ① 간호기록 요약',
    screenContent: [
      '"환자 A(80대 남성)의 간호기록을',
      '인수인계용으로 요약해줘"',
      '',
      '안전? / 위험?',
    ],
    script: `첫 번째 시나리오입니다.

"환자 A, 80대 남성의 간호기록을 인수인계용으로 요약해줘."

이건 안전합니까, 위험합니까?

잠시 생각해보십시오.

정답: 안전합니다. ⭕

왜 안전합니까?

하나씩 체크해보겠습니다.

개인정보: "환자 A"로 가명 처리됐습니다. 실명이 아닙니다. "80대"도 범위 표현입니다. 82세가 아니라 80대입니다.

요청 유형: "요약해줘"입니다. 판단 요청이 아니라 정리 요청입니다. 이미 있는 기록을 정리하는 겁니다.

결과물 용도: 인수인계용입니다. 이미 작성된 기록을 정리하는 업무입니다.

세 가지 다 안전 기준을 충족합니다.

이런 형태로 쓰시면 됩니다. 이게 모범 사례입니다.`,
  },

  {
    id: 12,
    phase: 'practice',
    title: '시나리오 ② 진단 판단 요청',
    screenContent: [
      '"70대 여성, 어지러움과 오심 증상.',
      '어떤 검사가 필요할까?"',
      '',
      '안전? / 위험?',
    ],
    script: `두 번째 시나리오입니다.

"70대 여성, 어지러움과 오심 증상. 어떤 검사가 필요할까?"

이건 안전합니까, 위험합니까?

잠시 생각해보십시오.

정답: 위험합니다. ❌

왜 위험합니까?

요청 유형을 보십시오.

"어떤 검사가 필요할까?"

이건 의료 판단 요청입니다.

증상을 보고 검사를 결정하는 건 의료인의 고유 영역입니다. AI가 하면 안 됩니다. 이건 정리가 아니라 판단입니다.

"근데 실명은 안 들어갔지 않습니까?"

맞습니다. 개인정보 측면에서는 괜찮습니다. "70대 여성"은 특정인이 아닙니다.

하지만 판단 요청이 문제입니다.

AI가 "이런 검사가 필요합니다"라고 대답하면, 그게 틀릴 수 있습니다. 의료 판단은 AI의 영역이 아닙니다.

교육 목적이라도 이런 형태는 피해야 합니다. 잘못된 정보가 머릿속에 남을 수 있습니다. 나중에 "그때 AI가 이렇게 말했는데..."하고 헷갈릴 수 있습니다.`,
  },

  {
    id: 13,
    phase: 'practice',
    title: '시나리오 ③ 안내문 작성',
    screenContent: [
      '"수술 전 금식 안내문을',
      '환자 보호자가 이해하기 쉽게 작성해줘"',
      '',
      '안전? / 위험?',
    ],
    script: `세 번째 시나리오입니다.

"수술 전 금식 안내문을 환자 보호자가 이해하기 쉽게 작성해줘."

이건 안전합니까, 위험합니까?

잠시 생각해보십시오.

정답: 안전합니다. ⭕

왜 안전합니까?

개인정보: 없습니다. 특정 환자를 지칭하지 않습니다. "수술 전 금식"은 일반적인 내용입니다.

요청 유형: "작성해줘"입니다. 일반적인 안내문 작성 요청입니다. 판단 요청이 아닙니다.

결과물 용도: 환자 보호자용 안내문입니다. 일반적인 정보 전달 문서입니다.

이런 업무는 AI가 가장 잘 도와주는 영역입니다.

2강에서 시연했던 것처럼, 안내문 작성은 AI의 강점입니다. 마음껏 활용하시면 됩니다.`,
  },

  {
    id: 14,
    phase: 'practice',
    title: '시나리오 ④ 사고보고서 작성',
    screenContent: [
      '"환자 김철수가 병실에서 낙상했어.',
      '사고보고서 써줘."',
      '',
      '안전? / 위험?',
    ],
    script: `네 번째 시나리오입니다.

"환자 김철수가 병실에서 낙상했어. 사고보고서 써줘."

이건 안전합니까, 위험합니까?

잠시 생각해보십시오.

정답: 위험합니다. ❌

왜 위험합니까?

두 가지 문제가 있습니다.

첫째, 실명 "김철수"가 그대로 들어갔습니다.

개인정보가 외부 AI 서버로 전송됩니다. 이것만으로도 이미 문제입니다.

둘째, 사고보고서는 법적 문서입니다.

낙상 사고보고서는 나중에 법적 분쟁이 생겼을 때 증거로 쓰일 수 있습니다. 보험 청구에도 쓰입니다. 이런 중요한 문서를 AI에게 "써줘"라고 맡기면 안 됩니다.

그러면 어떻게 바꾸면 됩니까?

"환자 A가 병실에서 낙상한 상황입니다. 사고보고서 초안 구조를 잡아주세요."

이렇게 바꾸면 안전해집니다.

1. 실명을 "환자 A"로 바꿨습니다 - 개인정보 보호
2. "사고보고서 써줘"가 아니라 "초안 구조를 잡아줘"로 바꿨습니다 - 책임 명확화

완성본이 아니라 초안을 요청하는 겁니다.

AI가 구조를 잡아주면, 그걸 바탕으로 사람이 실제 보고서를 작성합니다. 최종 책임은 사람이 집니다.`,
  },

  {
    id: 15,
    phase: 'practice',
    title: '시나리오 판단 핵심 정리',
    screenContent: [
      '| 체크 항목 | 안전 | 위험 |',
      '|----------|------|------|',
      '| 개인정보 | 가명/비식별 | 실명/특정가능 |',
      '| 요청 유형 | 정리/요약/초안 | 판단/결정/추천 |',
      '| 결과물 | 검토 후 사용 | 그대로 사용 |',
    ],
    script: `시나리오 판단의 핵심을 표로 정리하겠습니다.

이 표 하나만 기억하시면 대부분의 상황에서 판단할 수 있습니다.

개인정보:
- 안전: 가명이나 비식별 처리됨
- 위험: 실명이나 특정 가능

요청 유형:
- 안전: 정리, 요약, 초안
- 위험: 판단, 결정, 추천

결과물:
- 안전: 검토 후 사용
- 위험: 그대로 사용

AI 쓰기 전에 이 세 가지만 체크하십시오.

"개인정보 괜찮은가? 판단 요청 아닌가? 검토하고 쓸 것인가?"

세 개 다 "예"면 안전합니다. 하나라도 "아니오"면 다시 생각해보십시오.`,
  },

  {
    id: 16,
    phase: 'practice',
    title: '위험을 안전으로 바꾸는 방법',
    screenContent: [
      '위험 → 안전 변환 공식',
      '',
      '| 위험 요소 | 변환 방법 |',
      '|----------|----------|',
      '| 실명 | → "환자 A", "OOO" |',
      '| 구체적 나이 | → "80대", "70대" |',
      '| 진단 요청 | → "교육자료 작성" |',
      '| 처방 요청 | → "복약 안내문 작성" |',
      '| "작성해줘" | → "초안을 잡아줘" |',
    ],
    script: `위험한 요청을 안전하게 바꾸는 변환 공식을 정리해드리겠습니다.

이 표를 참고하시면, 위험한 프롬프트를 안전하게 바꿀 수 있습니다. 외워두시면 좋습니다.

실명 → "환자 A", "OOO"으로 가명 처리

구체적 나이 → "80대", "70대"로 범위 표현

진단 요청 → "교육자료 작성"으로 변환

처방 요청 → "복약 안내문 작성"으로 변환

"작성해줘" → "초안을 잡아줘"로 변환

특히 마지막이 중요합니다.

"작성해줘"를 "초안을 잡아줘"로 바꾸는 것.

이 한 단어 차이가 AI 결과물에 대한 책임 소재를 명확하게 해줍니다.

"작성해줘"라고 하면 AI가 완성본을 만드는 겁니다. 그걸 그대로 쓰면 문제가 될 수 있습니다.

"초안을 잡아줘"라고 하면 AI는 초안만 만들고, 완성은 사람이 하는 겁니다. 최종 책임이 사람에게 있다는 게 명확해집니다.

이 차이를 기억해주십시오.`,
  },

  // 정리 (6분)
  {
    id: 17,
    phase: 'summary',
    title: 'AI 결과물 활용의 원칙',
    screenContent: [
      'AI 결과물 = 초안',
      '',
      '아무리 잘 나와도 초안입니다.',
      '검토 → 수정 → 승인의 과정을 거쳐야 합니다.',
    ],
    script: `AI가 만들어준 결과물, 그대로 써도 됩니까?

"AI가 잘 만들어줬는데, 바로 쓰면 안 됩니까?"
"검토 안 하고 그대로 쓰면 더 빠르지 않습니까?"

답은 '아니오'입니다.

AI가 만든 결과물은 초안입니다. 아무리 잘 나와도 초안입니다. 완성본이 아닙니다.

왜 그렇습니까?

AI는 그럴듯하게 틀릴 수 있습니다. 의학 용어를 잘못 쓸 수도 있고, 우리 병원 상황에 안 맞는 내용이 들어갈 수도 있고, 책임 표현이 부적절하게 들어갈 수도 있습니다. 검토 없이 쓰면 이런 문제를 놓칩니다.

의료기관에서의 최종 문서는 반드시 사람이 확인하고 책임집니다.

AI는 도와주는 역할이고, 최종 판단과 책임은 항상 사람의 몫입니다.

이 원칙은 절대 바뀌지 않습니다. AI가 아무리 발전해도 이 원칙은 바뀌지 않습니다.`,
  },

  {
    id: 18,
    phase: 'summary',
    title: '윤리·보안은 제한이 아니라 가이드',
    screenContent: [
      '못 쓰게 하는 규칙 ❌',
      '안전하게 쓰는 기준 ⭕',
      '',
      '기록 요약 ⭕ / 문서 초안 ⭕ / 교육자료 정리 ⭕',
      '안내문 작성 ⭕ / 회의록 정리 ⭕ / 보고서 구조 잡기 ⭕',
    ],
    script: `오늘 내용을 들으시면서 이런 생각이 드셨을 수도 있습니다.

"이것도 안 되고 저것도 안 되네."
"결국 쓰지 말라는 거 아닙니까?"
"이래저래 조심해야 할 게 너무 많네."

아닙니다.

다시 생각해보십시오.

오늘 드린 건 "못 쓰게 하는 규칙"이 아닙니다.

"안전하게 쓰는 기준"입니다.

안 되는 것도 있지만, 되는 것도 많습니다.

기록 요약 - 됩니다.
문서 초안 - 됩니다.
교육자료 정리 - 됩니다.
안내문 작성 - 됩니다.
회의록 정리 - 됩니다.
보고서 구조 잡기 - 됩니다.

정리, 요약, 초안. 이 범위에서는 자유롭게 활용하십시오.

윤리와 보안은 AI 사용을 막기 위한 장치가 아닙니다.

안전하게 오래 쓰기 위한 가이드입니다.

기준을 알면, 그 안에서는 마음 편하게 쓸 수 있습니다. 기준이 없으면 불안하고, 기준이 있으면 자유롭습니다.`,
  },

  {
    id: 19,
    phase: 'summary',
    title: '오늘의 핵심 세 가지',
    screenContent: [
      '1. 개인정보는 입력하지 않는다',
      '2. 판단은 AI에게 맡기지 않는다',
      '3. 최종 책임은 사람이 진다',
    ],
    script: `오늘 4강의 핵심은 처음에 드린 세 가지 원칙 그대로입니다. 처음과 끝이 같습니다.

첫째, 개인정보는 입력하지 않는다.

실명, 주민번호, 연락처, 특정 가능한 정보 조합은 넣지 않습니다.

가명 처리하고, 비식별화하고, 예시 데이터를 쓰십시오.

둘째, 판단은 AI에게 맡기지 않는다.

진단, 처방, 결정은 AI가 하면 안 됩니다.

정리, 요약, 초안만 요청하십시오.

셋째, 최종 책임은 사람이 진다.

AI가 만든 결과물은 초안입니다.

검토하고, 수정하고, 승인하는 건 사람의 몫입니다.

이 세 가지만 지키시면 의료기관에서 AI를 안전하게 활용할 수 있습니다.`,
  },

  {
    id: 20,
    phase: 'summary',
    title: '마무리',
    screenContent: [
      '"기준을 알면 두렵지 않다"',
      '',
      '개인정보 입력 금지 / 판단 요청 금지 / 최종 책임은 사람이',
    ],
    script: `마무리하겠습니다.

오늘 핵심 한 문장입니다.

"AI는 기준 없이 쓰면 위험하고, 기준을 알면 두렵지 않다."

오늘 드린 기준을 기억해주십시오.

개인정보 입력 금지.
판단 요청 금지.
최종 책임은 사람이.

이 기준은 6강부터 실습할 때도 계속 적용됩니다. 실습하면서 "이거 해도 되나?" 싶을 때, 오늘 배운 기준으로 판단하시면 됩니다.

다음 강의에서는 병원에 AI를 도입한다는 것을 다루겠습니다. 개인을 넘어 조직 차원에서 AI를 쓰려면 무엇이 필요한지, 팀 차원에서 도입하려면 뭘 준비해야 하는지 이야기하겠습니다. 5강까지가 이론 파트이고, 6강부터는 본격적인 실습으로 들어갑니다.

감사합니다.`,
  },
];
